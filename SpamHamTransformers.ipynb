{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":260807,"sourceType":"datasetVersion","datasetId":109196}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport sklearn\nimport pandas as pd\nimport csv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:37:25.752241Z","iopub.execute_input":"2025-02-25T16:37:25.752594Z","iopub.status.idle":"2025-02-25T16:37:29.681869Z","shell.execute_reply.started":"2025-02-25T16:37:25.752567Z","shell.execute_reply":"2025-02-25T16:37:29.681185Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"SpamHam = pd.read_csv('/kaggle/input/spam-mails-dataset/spam_ham_dataset.csv')\nSpamHam.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:37:29.682971Z","iopub.execute_input":"2025-02-25T16:37:29.683455Z","iopub.status.idle":"2025-02-25T16:37:29.847641Z","shell.execute_reply.started":"2025-02-25T16:37:29.683425Z","shell.execute_reply":"2025-02-25T16:37:29.846798Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0 label                                               text  \\\n0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n\n   label_num  \n0          0  \n1          0  \n2          0  \n3          1  \n4          0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>label</th>\n      <th>text</th>\n      <th>label_num</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>605</td>\n      <td>ham</td>\n      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2349</td>\n      <td>ham</td>\n      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3624</td>\n      <td>ham</td>\n      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4685</td>\n      <td>spam</td>\n      <td>Subject: photoshop , windows , office . cheap ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2030</td>\n      <td>ham</td>\n      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import re\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score\n\n\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(r'[^a-z\\s]', '', text)\n    text = re.sub(r'\\s+', ' ', text).strip()\n    return text\n\nSpamHam['clean_text'] = SpamHam['text'].apply(clean_text)\nSpamHam['clean_text'].head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:37:29.849348Z","iopub.execute_input":"2025-02-25T16:37:29.849572Z","iopub.status.idle":"2025-02-25T16:37:30.465727Z","shell.execute_reply.started":"2025-02-25T16:37:29.849546Z","shell.execute_reply":"2025-02-25T16:37:30.464889Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"0    subject enron methanol meter this is a follow ...\n1    subject hpl nom for january see attached file ...\n2    subject neon retreat ho ho ho we re around to ...\n3    subject photoshop windows office cheap main tr...\n4    subject re indian springs this deal is to book...\nName: clean_text, dtype: object"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"\ndef create_vocab(texts):\n    vocab = set()\n    for text in texts:\n        words = text.split()\n        vocab.update(words)\n    return {word: idx for idx, word in enumerate(sorted(vocab))}\n\ndef text_to_bow(text, vocab):\n    vector = torch.zeros(len(vocab))\n    for word in text.split():\n        if word in vocab:\n            vector[vocab[word]] += 1\n    return vector\n\nvocabulary = create_vocab(SpamHam['clean_text'])\nX = torch.stack([text_to_bow(text, vocabulary) for text in SpamHam['clean_text']])\nprint(X)\ny = torch.tensor(SpamHam['label_num'].values)\nprint(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:37:30.466655Z","iopub.execute_input":"2025-02-25T16:37:30.466923Z","iopub.status.idle":"2025-02-25T16:37:39.984082Z","shell.execute_reply.started":"2025-02-25T16:37:30.466891Z","shell.execute_reply":"2025-02-25T16:37:39.983160Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n        [11.,  0.,  0.,  ...,  0.,  0.,  0.],\n        ...,\n        [ 1.,  0.,  0.,  ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.],\n        [ 0.,  0.,  0.,  ...,  0.,  0.,  0.]])\ntensor([0, 0, 0,  ..., 0, 0, 1])\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn.functional as F\nimport os\nos.environ['WANDB_DISABLED'] = 'true'\n\n\n\nclass SpamHamDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            truncation=True,\n            return_token_type_ids=False,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt',\n        )\n        return {\n            'text': text,\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\ntrain_dataset = SpamHamDataset(SpamHam['clean_text'].values, SpamHam['label_num'].values, tokenizer, max_len=128)\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',\n    num_train_epochs=3,\n    per_device_train_batch_size=128,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir='./logs',\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n)\n\ntrainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:37:39.984970Z","iopub.execute_input":"2025-02-25T16:37:39.985290Z","iopub.status.idle":"2025-02-25T16:41:41.586503Z","shell.execute_reply.started":"2025-02-25T16:37:39.985261Z","shell.execute_reply":"2025-02-25T16:41:41.585405Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36fce64be78c418c89f60d9367c51391"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5e25740b51d4a259cb80338d39b04d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bbaed6fb10b4a89825afe217b926591"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7d25e769870c45929c02b91b6f0a0dba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"197747eb30854521aea05880ff0959a9"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [123/123 03:35, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=123, training_loss=0.3774718928143261, metrics={'train_runtime': 218.4711, 'train_samples_per_second': 71.007, 'train_steps_per_second': 0.563, 'total_flos': 1020410450449920.0, 'train_loss': 0.3774718928143261, 'epoch': 3.0})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix\n\ntest_dataset = SpamHamDataset(SpamHam['clean_text'].values, SpamHam['label_num'].values, tokenizer, max_len=128)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nmodel.eval()\npredictions, true_labels = [], []\n\nfor batch in test_loader:\n    inputs = batch['input_ids'].to('cuda')\n    masks = batch['attention_mask'].to('cuda')\n    labels = batch['labels'].to('cuda')\n\n    with torch.no_grad():\n        outputs = model(inputs, attention_mask=masks)\n    logits = outputs.logits\n    predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n    true_labels.extend(labels.cpu().numpy())\n\nprint('Classification Report:')\nprint(classification_report(true_labels, predictions))\nprint('Confusion Matrix:')\nprint(confusion_matrix(true_labels, predictions))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-25T16:43:14.904418Z","iopub.execute_input":"2025-02-25T16:43:14.904732Z","iopub.status.idle":"2025-02-25T16:43:49.475897Z","shell.execute_reply.started":"2025-02-25T16:43:14.904706Z","shell.execute_reply":"2025-02-25T16:43:49.474995Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n              precision    recall  f1-score   support\n\n           0       1.00      0.99      0.99      3672\n           1       0.97      0.99      0.98      1499\n\n    accuracy                           0.99      5171\n   macro avg       0.98      0.99      0.99      5171\nweighted avg       0.99      0.99      0.99      5171\n\nConfusion Matrix:\n[[3631   41]\n [  14 1485]]\n","output_type":"stream"}],"execution_count":8}]}