{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SpamHam = pd.read_csv('spam_ham_dataset.csv')\n",
    "SpamHam.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "SpamHam['clean_text'] = SpamHam['text'].apply(clean_text)\n",
    "SpamHam['clean_text'].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab(texts):\n",
    "    vocab = set()\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "        vocab.update(words)\n",
    "    return {word: idx for idx, word in enumerate(sorted(vocab))}\n",
    "\n",
    "def text_to_bow(text, vocab):\n",
    "    vector = torch.zeros(len(vocab))\n",
    "    for word in text.split():\n",
    "        if word in vocab:\n",
    "            vector[vocab[word]] += 1\n",
    "    return vector\n",
    "\n",
    "vocabulary = create_vocab(SpamHam['clean_text'])\n",
    "X = torch.stack([text_to_bow(text, vocabulary) for text in SpamHam['clean_text']])\n",
    "y = torch.tensor(SpamHam['label_num'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert PyTorch tensors to NumPy arrays for scikit-learn\n",
    "X_train_np = X_train.numpy()\n",
    "X_test_np = X_test.numpy()\n",
    "y_train_np = y_train.numpy()\n",
    "y_test_np = y_test.numpy()\n",
    "\n",
    "# Initialize and train the Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_np)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test_np, y_pred)\n",
    "print(f'Random Forest Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Display classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test_np, y_pred, target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test_np, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom PyTorch implementation of a Decision Tree\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=5, min_samples_split=2, criterion='gini'):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.tree = None\n",
    "    \n",
    "    def gini_impurity(self, y):\n",
    "        # Calculate Gini impurity\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        proportion = torch.bincount(y) / len(y)\n",
    "        return 1 - torch.sum(proportion ** 2)\n",
    "    \n",
    "    def entropy(self, y):\n",
    "        # Calculate entropy\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        proportion = torch.bincount(y) / len(y)\n",
    "        # Filter out zero proportions to avoid log(0)\n",
    "        log_probs = torch.log2(proportion[proportion > 0])\n",
    "        return -torch.sum(proportion[proportion > 0] * log_probs)\n",
    "    \n",
    "    def find_best_split(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "        if depth >= self.max_depth or n_samples < self.min_samples_split or len(torch.unique(y)) == 1:\n",
    "            return None, self._leaf_value(y)\n",
    "        \n",
    "        best_gain = -float('inf')\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        \n",
    "        # Calculate current impurity\n",
    "        if self.criterion == 'gini':\n",
    "            current_impurity = self.gini_impurity(y)\n",
    "        else:  # entropy\n",
    "            current_impurity = self.entropy(y)\n",
    "            \n",
    "        # For each feature\n",
    "        for feature in range(n_features):\n",
    "            # Get unique values for the feature\n",
    "            thresholds = torch.unique(X[:, feature])\n",
    "            \n",
    "            # For each possible threshold\n",
    "            for threshold in thresholds:\n",
    "                # Split the data\n",
    "                left_idx = X[:, feature] <= threshold\n",
    "                right_idx = ~left_idx\n",
    "                \n",
    "                # Skip if split is empty\n",
    "                if torch.sum(left_idx) == 0 or torch.sum(right_idx) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate impurity for children\n",
    "                if self.criterion == 'gini':\n",
    "                    left_impurity = self.gini_impurity(y[left_idx])\n",
    "                    right_impurity = self.gini_impurity(y[right_idx])\n",
    "                else:  # entropy\n",
    "                    left_impurity = self.entropy(y[left_idx])\n",
    "                    right_impurity = self.entropy(y[right_idx])\n",
    "                \n",
    "                # Calculate weighted impurity\n",
    "                n_left = torch.sum(left_idx)\n",
    "                n_right = torch.sum(right_idx)\n",
    "                weighted_impurity = (n_left / n_samples) * left_impurity + (n_right / n_samples) * right_impurity\n",
    "                \n",
    "                # Calculate information gain\n",
    "                gain = current_impurity - weighted_impurity\n",
    "                \n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        if best_gain <= 0:\n",
    "            return None, self._leaf_value(y)\n",
    "        \n",
    "        return (best_feature, best_threshold), None\n",
    "    \n",
    "    def _leaf_value(self, y):\n",
    "        # Return the most common class\n",
    "        return torch.bincount(y).argmax().item()\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        # Find the best split\n",
    "        best_split, leaf_value = self.find_best_split(X, y, depth)\n",
    "        \n",
    "        # If we can't split further, return a leaf node\n",
    "        if best_split is None:\n",
    "            return {'leaf_value': leaf_value}\n",
    "        \n",
    "        feature, threshold = best_split\n",
    "        \n",
    "        # Split the data\n",
    "        left_idx = X[:, feature] <= threshold\n",
    "        right_idx = ~left_idx\n",
    "        \n",
    "        # Recursively build the left and right branches\n",
    "        left_branch = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        right_branch = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "        \n",
    "        return {'feature': feature, 'threshold': threshold, 'left': left_branch, 'right': right_branch}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.tree = self._build_tree(X, y)\n",
    "        return self\n",
    "    \n",
    "    def _predict_sample(self, x, node):\n",
    "        # If we're at a leaf node\n",
    "        if 'leaf_value' in node:\n",
    "            return node['leaf_value']\n",
    "        \n",
    "        # Otherwise, navigate the tree\n",
    "        if x[node['feature']] <= node['threshold']:\n",
    "            return self._predict_sample(x, node['left'])\n",
    "        else:\n",
    "            return self._predict_sample(x, node['right'])\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return torch.tensor([self._predict_sample(x, self.tree) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch implementation of Random Forest\n",
    "class PyTorchRandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=5, min_samples_split=2, criterion='gini'):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.criterion = criterion\n",
    "        self.trees = []\n",
    "    \n",
    "    def _bootstrap_sample(self, X, y):\n",
    "        n_samples = X.shape[0]\n",
    "        # Sample with replacement\n",
    "        indices = torch.randint(0, n_samples, (n_samples,))\n",
    "        return X[indices], y[indices]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_estimators):\n",
    "            # Bootstrap sample\n",
    "            X_sample, y_sample = self._bootstrap_sample(X, y)\n",
    "            \n",
    "            # Create and train a decision tree\n",
    "            tree = DecisionTree(max_depth=self.max_depth, \n",
    "                               min_samples_split=self.min_samples_split,\n",
    "                               criterion=self.criterion)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            \n",
    "            # Add tree to forest\n",
    "            self.trees.append(tree)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # Collect predictions from all trees\n",
    "        predictions = torch.zeros(X.shape[0], self.n_estimators, dtype=torch.long)\n",
    "        \n",
    "        for i, tree in enumerate(self.trees):\n",
    "            predictions[:, i] = tree.predict(X)\n",
    "        \n",
    "        # Use majority vote to make final prediction\n",
    "        final_pred = torch.zeros(X.shape[0], dtype=torch.long)\n",
    "        for i in range(X.shape[0]):\n",
    "            final_pred[i] = torch.bincount(predictions[i]).argmax()\n",
    "        \n",
    "        return final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train our custom PyTorch Random Forest model\n",
    "torch_rf = PyTorchRandomForest(n_estimators=10, max_depth=5)\n",
    "torch_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_torch_pred = torch_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "torch_accuracy = accuracy_score(y_test.numpy(), y_torch_pred.numpy())\n",
    "print(f'PyTorch Random Forest Accuracy: {torch_accuracy:.4f}')\n",
    "\n",
    "# Display classification report\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test.numpy(), y_torch_pred.numpy(), target_names=['Ham', 'Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for PyTorch Random Forest\n",
    "torch_cm = confusion_matrix(y_test.numpy(), y_torch_pred.numpy())\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(torch_cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Ham', 'Spam'], \n",
    "            yticklabels=['Ham', 'Spam'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix for PyTorch Random Forest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare scikit-learn and PyTorch implementations\n",
    "print(f'scikit-learn Random Forest Accuracy: {accuracy:.4f}')\n",
    "print(f'PyTorch Random Forest Accuracy: {torch_accuracy:.4f}')\n",
    "\n",
    "# Plot feature importances from scikit-learn model\n",
    "feature_importances = rf_model.feature_importances_\n",
    "# Get the top 20 features\n",
    "indices = np.argsort(feature_importances)[-20:]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.title('Top 20 Feature Importances')\n",
    "plt.barh(range(len(indices)), feature_importances[indices], align='center')\n",
    "\n",
    "# Convert indices to words for better visualization\n",
    "words = [list(vocabulary.keys())[i] for i in indices]\n",
    "plt.yticks(range(len(indices)), words)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
